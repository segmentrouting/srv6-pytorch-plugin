apiVersion: batch/v1
kind: Job
metadata:
  name: pytorch-distributed-training
spec:
  completions: 1
  parallelism: 1
  template:
    spec:
      containers:
      - name: pytorch
        image: pytorch-srv6-demo:latest
        command: ["python", "/app/entrypoint.py", "/app/test_plugin.py"]
        envFrom:
        - configMapRef:
            name: pytorch-distributed-config
        env:
        - name: MASTER_ADDR
          value: "2001:db8:1000::2"  # IPv6 address of master node
        - name: RANK
          value: "0"  # For a single job, we'll use rank 0
        volumeMounts:
        - name: training-code
          mountPath: /app
      volumes:
      - name: training-code
        configMap:
          name: training-code
      restartPolicy: Never